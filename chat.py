import streamlit as st
import openai
from dotenv import load_dotenv
import nltk
import os
import tempfile
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
import PyPDF2
import time
from google.cloud import texttospeech

# Configuraci√≥n de NLTK
nltk.download('punkt')
nltk.download('stopwords')

# Funci√≥n para cargar el texto del PDF
def extraer_texto_pdf(archivo):
    texto = ""
    if archivo:
        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            temp_file.write(archivo.read())
            temp_file_path = temp_file.name
        with open(temp_file_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            for page in range(len(reader.pages)):
                texto += reader.pages[page].extract_text()
        os.unlink(temp_file_path)
    return texto

# Funci√≥n para preprocesar texto
def preprocesar_texto(texto):
    tokens = word_tokenize(texto, language='spanish')
    tokens = [word.lower() for word in tokens if word.isalpha()]
    stopwords_es = set(stopwords.words('spanish'))
    tokens = [word for word in tokens if word not in stopwords_es]
    stemmer = SnowballStemmer('spanish')
    tokens = [stemmer.stem(word) for word in tokens]
    return " ".join(tokens)

# Cargar la clave API desde el archivo .env
load_dotenv()
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "botidinamix-g.json" # Reemplaza 'key.json' con el nombre de tu archivo de credenciales
openai.api_key = os.getenv("OPENAI_API_KEY")

# Instancia el cliente de Text-to-Speech
client = texttospeech.TextToSpeechClient()

# Funci√≥n para obtener respuesta de OpenAI usando el modelo GPT y convertir a audio
def obtener_respuesta(pregunta, texto_preprocesado, modelo, temperatura=0.5):
    try:
        response = openai.ChatCompletion.create(
            model=modelo,
            messages=[
                {"role": "system", "content": "Actua como Galatea la asistente de la clinica Odontologica OMARDENT y resuelve las inquietudes"},
                {"role": "user", "content": f"{pregunta}\n\nContexto: {texto_preprocesado}"}
            ],
            temperature=temperatura
        )
        respuesta = response.choices[0].message['content'].strip()

        # Configura la solicitud de s√≠ntesis de voz
        input_text = texttospeech.SynthesisInput(text=respuesta)
        voice = texttospeech.VoiceSelectionParams(
            language_code="es-ES", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )

        # Realiza la solicitud de s√≠ntesis de voz
        response = client.synthesize_speech(
            input=input_text, voice=voice, audio_config=audio_config
        )

        # Reproduce el audio en Streamlit
        st.audio(response.audio_content, format="audio/mp3")
        return respuesta

    except openai.OpenAIError as e:
        st.error(f"Error al comunicarse con OpenAI: {e}")
        return "Lo siento, no puedo procesar tu solicitud en este momento."

def main():
    # --- Dise√±o general ---
    st.set_page_config(page_title="Asistente Virtual", page_icon="ü§ñ")

    # --- Barra lateral ---
    with st.sidebar:
        st.image("logo omardent.png")
        st.title("ü§ñ Asistente Virtual BOTIDINAMIX AI")
        st.markdown("---")

        # Selecci√≥n de modelo de lenguaje
        st.subheader("üß† Configuraci√≥n del Modelo")
        modelo = st.selectbox(
            "Selecciona el modelo:",
            ["gpt-3.5-turbo", "gpt-4"],
            index=0,
            help="Elige el modelo de lenguaje de OpenAI que prefieras."
        )

        # --- Opciones adicionales ---
        st.markdown("---")
        temperatura = st.slider("üå°Ô∏è Temperatura", min_value=0.0, max_value=1.0, value=0.5, step=0.1)

    # --- Video de fondo ---
    with st.container():
        st.markdown(
            f"""
            <style>
            #video-container {{
                position: relative;
                width: 100%;
                padding-bottom: 56.25%; /* Relaci√≥n de aspecto 16:9 */
                background-color: lightblue; /* Fondo azul claro */
                overflow: hidden;  /* Evita que el video se desborde */
            }}
            #background-video {{
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
            }}
            </style>
            <div id="video-container">
                <video id="background-video" autoplay loop muted playsinline>
                    <source src="https://cdn.leonardo.ai/users/645c3d5c-ca1b-4ce8-aefa-a091494e0d09/generations/89dda365-bf17-4867-87d4-bd918d4a2818/89dda365-bf17-4867-87d4-bd918d4a2818.mp4" type="video/mp4">
                </video>
            </div>
            """,
            unsafe_allow_html=True,
        )

    # --- √Årea principal de la aplicaci√≥n ---
    st.header("üí¨ Hablar con Galatea OMARDENT")

    # Carga de archivo PDF
    archivo_pdf = st.file_uploader("üìÇ Cargar PDF", type='pdf')

    # --- Chatbot ---
    if 'mensajes' not in st.session_state:
        st.session_state.mensajes = []

    for mensaje in st.session_state.mensajes:
        with st.chat_message(mensaje["role"]):
            st.markdown(mensaje["content"])

    pregunta_usuario = st.chat_input("Pregunta:")
    if pregunta_usuario:
        st.session_state.mensajes.append({"role": "user", "content": pregunta_usuario})
        with st.chat_message("user"):
            st.markdown(pregunta_usuario)

        if archivo_pdf:
            texto_pdf = extraer_texto_pdf(archivo_pdf)
            texto_preprocesado = preprocesar_texto(texto_pdf)
        else:
            texto_preprocesado = ""  # Sin contexto de PDF si no se carga un archivo

        respuesta = obtener_respuesta(pregunta_usuario, texto_preprocesado, modelo, temperatura)
        st.session_state.mensajes.append({"role": "assistant", "content": respuesta})
        with st.chat_message("assistant"):
            st.markdown(respuesta)

if __name__ == "__main__":
    main()
